#machine_learning #notes #class
Path so far
Linear Regression -> Linear Regression with Probability -> If you assume probability distribution, you can use the same recipe in Linear Regression
## Introduction
Logistic regression is a statistical method used for **binary classification**. It models the probability that a dependent variable belongs to a particular category.

Given 
$$
\{(x^{(i)}, y^{(i)}) \text{ for } i = 1...n\} \text{ and } x^{(i)} \in \mathbb{R}^{d+1}, y^{(i)} \in \{0, 1\}
$$

We want $h_{\theta}(x) \in [0, 1]$
$$h_\theta(x) = g(\theta^Tx) = \frac{1}{1 + e^{-\theta^Tx}}$$
So then you get $$g(z) = \frac{1}{1+e^{-z}}$$
which is called the "link function" / sigmoid / logistic function and it stays inside the 0, 1 interested region. This is a model you have chosen, you could substitute other models in here. 

This gives you the probability distribution of
$$\displaylines{P(y=1 | x_j\theta) = h_\theta(x) \\ P(y = 0 | x_j\theta) = 1 - h_\theta(x)}$$

You then know that you likelihood function and can use Gradient Descent ([[1. Linear Regression]]) to find the parameters, also know as Maximum Log Likelihood.

$$\begin{align} \mathcal{L}(\theta) & = p(y | x_j\theta) = \prod_{i=1}^{n} p(y^{(i)} | x^{(i)}_j\theta) \\ 
& = \prod_{i=1}^{n}h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)})^{1 - y^{(i)}}\end{align}$$
Then you can take the log of $\mathcal{L}(\theta)$
$$\mathcal{l}(\theta) = \sum_{i=1}^ny^{(i)}\log(h_\theta(x^{(i)}) + (1 - y^{(i)})\log(1-h_\theta(x^{(i)}))$$
>> I am missing something here: I don't really understand WHY you'd take the log of this, nor why the last x is to the \theta and not i. I suspect this is in the section "Linear Regression with Probability"

## Newton's Method
- Also an iterative method used to solve these problems for a long time.
- Quadratic convergence (extremely fast). 
- Computationally challenging, so being used less, because you need to compute the Hessian on every step (now we generally use stochastic gradient descent). n and d (features and data points) are huge, like billions. 
in one dimension, it's great. Find derivative, find zero, move to the point on the function where the zero is. 
In the context of logistic regression and multivariable optimization using Newton's method, the update equation for the parameter vector \(\theta\) may indeed refer to the current parameter values \(\theta_k\) more than once within a single iteration of the update process. This is due to the need to use both the gradient and the Hessian of the loss function, which are both functions of \(\theta_k\). However, it's important to clarify how each component is used and the role of \(\theta_k\) in the update formula.

Here's a breakdown:

### Logistic Regression Update Formula:
In logistic regression using Newton's method, the update formula is:
$$\theta_{k+1} = \theta_k - H^{-1}(\theta_k) \nabla J(\theta_k)$$
where:
- $\theta_k$ is the vector of parameters at the \(k\)-th iteration.
- $\nabla J(\theta_k)$ is the gradient of the loss function \(J\) evaluated at $\theta_k$. This gradient is a vector of first partial derivatives of \(J\) with respect to each element in \(\theta\).
- $H^{-1}(\theta_k)$ is the inverse of the Hessian matrix of \(J\) evaluated at \(\theta_k\). The Hessian matrix is a square matrix containing second partial derivatives of \(J\).

### Components Explained:
1. **Gradient (\(\nabla J(\theta_k)\))**:
   - This vector points in the direction of steepest ascent of the loss function at \(\theta_k\).
   - For logistic regression, specifically, the gradient can be derived from the difference between predicted probabilities and actual labels, weighted by the respective features.

2. **Hessian Matrix (\(H(\theta_k)\))**:
   - This matrix provides information about the curvature of the loss function at \(\theta_k\).
   - In logistic regression, the Hessian matrix elements are computed from the predicted probabilities, indicating how 'sensitive' the predictions are to changes in the parameters across the feature space.

3. **Update Step**:
   - The product \(H^{-1}(\theta_k) \nabla J(\theta_k)\) essentially scales the gradient by the inverse of the Hessian matrix. This scaling adjusts the raw gradient descent step based on the curvature of the loss surface, allowing for more informed steps towards the minimum that are likely to be stable and efficient.

### Importance of \( \theta_k \) Usage:
- The repeated use of \(\theta_k\) in computing both \(H\) and \(\nabla J\) and then applying it in the update formula reflects the iterative nature of Newton's method.
- Each iteration uses the current estimate \(\theta_k\) to compute both the direction to move (via the gradient) and the optimal step size (informed by the Hessian). This ensures that each step is both in the right direction and of the right magnitude, given the local topology of the loss landscape.

This approach generally results in faster convergence compared to simpler methods like gradient descent, especially near the minimum, because it accounts for the second-order properties of the loss function (its curvature), which dictate how the parameter space should be navigated.

### Generalize to Vector Case
Give $f : \mathbb{R}^d \rightarrow \mathbb{R}$ 

## Mathematical Model
The logistic model predicts the probability $p$ that the outcome variable $y$ is 1 given predictor $x$. The model is expressed using the logistic function derived from the likeli function.

$$
\log\left(\frac{p}{1-p}\right) = \theta_0 + \theta_1 x \\
$$

where:
- $p = P(y = 1 | x)$ is the conditional probability that $y = 1$ given $x$.
- $x$ is the predictor variable.
- $\theta_0$ and $\theta_1$ are the model coefficients.

## Probability Estimation
The conditional probability $p$ that $y = 1$ given $x$ can be derived from the logistic function:

$$
p = P(y = 1 | x) = \frac{1}{1 + e^{-(\theta_0 + \theta_1 x)}} \\
$$

This function outputs values between 0 and 1, making it suitable for probability estimation.

## Interpretation
The coefficients $\theta_0$ and $\theta_1$ can be interpreted as follows:

- $\theta_0$ adjusts the logistic curve along the x-axis.
- $\theta_1$ determines the steepness of the logistic curve. A positive $\theta_1$ indicates that as $x$ increases, the probability of $y = 1$ increases.

# Generating Logistic Regression Model Using Gradient Descent

## Introduction
Logistic regression, unlike linear regression, is used for binary classification tasks. The outcome is modeled as a probability that the dependent variable belongs to a particular class, typically 0 or 1.

## Logistic Regression vs. Linear Regression
While linear regression outputs a continuous value, logistic regression uses the logistic function (also known as the sigmoid function) to ensure that the output remains between 0 and 1, making it interpretable as a probability.

## Logistic Function
The logistic (sigmoid) function is defined as:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

For logistic regression, the model prediction formula is:

$$
p = \sigma(\theta^T x) = \frac{1}{1 + e^{-\theta^T x}}
$$

where:
- $\theta^T x$ is the dot product of the feature vector $x$ and the coefficient vector $\theta$.
- $p$ represents the probability that the dependent variable $y = 1$ given $x$.

## Objective Function
The goal in logistic regression is to minimize the cost function, which is typically the binary cross-entropy loss (also known as the log loss):

$$
J(\theta) = -\frac{1}{m} \sum_{i=1}^m [y^{(i)} \log(p^{(i)}) + (1 - y^{(i)}) \log(1 - p^{(i)})]
$$

where:
- $m$ is the number of training examples.
- $y^{(i)}$ is the actual class label for the $i$-th example.
- $p^{(i)}$ is the predicted probability that $y^{(i)} = 1$.

## Gradient Descent
To minimize $J(\theta)$, gradient descent is used to update the parameters $\theta$. The update rule at each iteration is:

$$
\theta = \theta - \alpha \nabla_\theta J(\theta)
$$

where:
- $\alpha$ is the learning rate.
- $\nabla_\theta J(\theta)$ is the gradient of $J(\theta)$ with respect to $\theta$.

### Computing the Gradient
The gradient of the cost function for logistic regression is given by:

$$
\nabla_\theta J(\theta) = \frac{1}{m} \sum_{i=1}^m (p^{(i)} - y^{(i)}) x^{(i)}
$$

This indicates how $\theta$ should be adjusted to reduce the cost.

## Algorithm Steps
1. **Initialize** $\theta$ (often to zero or small random values).
2. **Repeat** until convergence:
   - Calculate the predicted probabilities $p^{(i)}$ for each training example using the current $\theta$.
   - Update $\theta$ using the gradient descent update rule.

## Conclusion
Gradient descent provides a method to learn the parameters of a logistic regression model, optimizing the prediction accuracy for binary classification tasks by iteratively minimizing the cost function.
